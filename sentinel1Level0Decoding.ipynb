{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c031b5af",
   "metadata": {},
   "source": [
    "# Sentinel-1 Level 0 Data Decoding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40341a1",
   "metadata": {},
   "source": [
    "Sentinel-1 is a Synthetic Aperture Mapping satellite constellation operated by the European Space Agency (ESA). ESA publish several types of product associated with each data acquisition. Level 1 and Level 2 data files consist of various types of processed SAR images, but the raw packetized data downlinked to the ground is also available in the form of Level 0 products.\n",
    "\n",
    "ESA also publish details of the [image formation algorithm used to generate Level 1 products](https://sentinels.copernicus.eu/web/sentinel/user-guides/document-library/-/asset_publisher/xlslt4309D5h/content/id/4629294?_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_redirect=https%3A%2F%2Fsentinels.copernicus.eu%2Fweb%2Fsentinel%2Fuser-guides%2Fdocument-library%3Fp_p_id%3Dcom_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h%26p_p_lifecycle%3D0%26p_p_state%3Dnormal%26p_p_mode%3Dview%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_cur%3D2%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_delta%3D10%26p_r_p_resetCur%3Dfalse%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_assetEntryId%3D4629294) and [structure of Sentinel-1 data packets](https://sentinels.copernicus.eu/web/sentinel/user-guides/document-library/-/asset_publisher/xlslt4309D5h/content/id/3120468?_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_redirect=https%3A%2F%2Fsentinels.copernicus.eu%2Fweb%2Fsentinel%2Fuser-guides%2Fdocument-library%3Fp_p_id%3Dcom_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h%26p_p_lifecycle%3D0%26p_p_state%3Dnormal%26p_p_mode%3Dview%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_cur%3D13%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_delta%3D10%26p_r_p_resetCur%3Dfalse%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xlslt4309D5h_assetEntryId%3D3120468) in their [document library](https://sentinels.copernicus.eu/web/sentinel/user-guides/document-library).\n",
    "\n",
    "This notebook demonstrates data extraction from Level 0 products using the Sentinel1Decoder Python code at https://github.com/Rich-Hall/sentinel1decoder. An example implementation of the range-Doppler algorithm is also provided to demonstrate image formation from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b46537",
   "metadata": {},
   "source": [
    "## 1 - Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentinel1decoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import cmath\n",
    "import struct\n",
    "import os as system\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"\"\n",
    "filename = \"S1A_IW_RAW__0SDV_20240609T180612_20240609T180644_054250_06993F_39D8\\s1a-iw-raw-s-vh-20240609t180612-20240609t180644-054250-06993f-annot.dat\"\n",
    "#filepath = \"../data/russia/\"\n",
    "#filename = \"s1a-iw-raw-s-vh-20230307t152137-20230307t152158-047540-05b562.dat\"\n",
    "\n",
    "inputfile = \"S1A_S3_RAW__0SDH_20240617T213605.SAFE\\S1A_S3_RAW__0SDH_20240617T213605_20240617T213630_054368_069D4F_ABA9.SAFE\\s1a-s3-raw-s-hh-20240617t213605-20240617t213630-054368-069d4f.dat\"\n",
    "l0file = sentinel1decoder.Level0File(inputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373f40c",
   "metadata": {},
   "source": [
    "## 2 - Extract File Metadata\n",
    "\n",
    "Sentinel-1 level 0 data files consist of the raw packetized data sent to the ground. One packet typically consists of the radar instrument output associated with one radar echo, so a single file typically consists of many thousands of packets. Packets may also consist of other types of data e.g. background noise measurements for instrument calibration.\n",
    "\n",
    "We are working with data acquired in stripmap mode over Sao Paulo and the nearby port of Santos, Brazil. Stripmap data is mainly used to monitor small islands, so is relatively infrequently used. However, it is relatively simple compared to Interferometric Wide Swath mode, the main acquisiton mode used over land, and therefore makes our task of image formation much simpler!\n",
    "\n",
    "Initially we're going to pull the metadata from each packet and output to a Pandas dataframe to examine the file contents. Producing an image from the entirity of the data found in a single file would take a long time and require a lot of memory, so we're aiming to produce an image from just a subset of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0file.packet_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d121b6a6",
   "metadata": {},
   "source": [
    "The satellite ephemeris data is sub-commutated across multiple packets due to its relatively low update rate, so we need to perform an extra step to extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0file.ephemeris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0415d49",
   "metadata": {},
   "source": [
    "## 3 - Extract Data\n",
    "\n",
    "### 3.1 - Select Packets to Process\n",
    "\n",
    "Now we've extracted all the packet metadata, we're going to select the data packets we'll be processing. We want to exclude all packets that don't contain SAR instrument returns, and then pick a small set of these to operate on. For this example we'll be focusing on the coastline around the port of Santos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_burst = 8\n",
    "selection = l0file.get_burst_metadata(selected_burst)\n",
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b315a",
   "metadata": {},
   "source": [
    "### 3.2 - Extract Raw I/Q Sensor Data\n",
    "\n",
    "Now we're ready to extract the raw sensor output from the file. The result will be a set of complex I/Q samples measured by the SAR instrument. By stacking these horizontally we can produce a 2D array of data samples, with fast time $\\tau$ along one axis and slow time $\\eta$ along the other. Since all the required information to do this is contained in packet metadata, the decoder outputs data arranged like this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6520fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the IQ data\n",
    "original_radar_data = l0file.get_burst_data(selected_burst, True)\n",
    "\n",
    "# Cache this data so we can retrieve it more quickly next time we want it\n",
    "# l0file.save_burst_data(selected_burst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33131272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l0file.save_burst_data(selected_burst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cf8eb",
   "metadata": {},
   "source": [
    "Plotting our array, we can see that although there is clearly some structure to the data, we can't yet make out individual features. Our image needs to be focused along both the range and azimuth axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the data\n",
    "slow_time_truncated = int(original_radar_data.shape[1] * 0.2)\n",
    "radar_data = original_radar_data[:, :slow_time_truncated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 10**(5/10)\n",
    "\n",
    "def generate_thermal_noise(shape, sigma):\n",
    "    noise_real = np.random.normal(0, sigma, shape)\n",
    "    noise_imag = np.random.normal(0, sigma, shape)\n",
    "    return noise_real + 1j * noise_imag\n",
    "\n",
    "mean_value = np.mean(abs(radar_data)**2)\n",
    "additional_noise_power = mean_value / SNR\n",
    "additional_noise = generate_thermal_noise(radar_data.shape, np.sqrt(additional_noise_power/2))\n",
    "\n",
    "# Add noise to radar data\n",
    "radar_data += additional_noise\n",
    "\n",
    "# Plot the noisy IQ data\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"Noisy Sentinel-1 Raw I/Q Sensor Output\")\n",
    "plt.imshow(abs(radar_data[:, :]), vmin=0, vmax=15, origin='lower', )\n",
    "plt.xlabel(\"Fast Time (down range)\")\n",
    "plt.ylabel(\"Slow Time (cross range)\")\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958d241",
   "metadata": {},
   "source": [
    "## 4 - Image Processing\n",
    "\n",
    "The following section demonstrates an implementation of the range-Doppler algorithm. This essentially consists of the following steps:\n",
    "- Range compression\n",
    "- Transform to range-Doppler domain\n",
    "- Range Cell Migration Correction (RCMC)\n",
    "- Azimuth compression\n",
    "- Transform to time domain\n",
    "- Image formation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652a38b",
   "metadata": {},
   "source": [
    "### 4.1 - Define auxiliary parameters\n",
    "\n",
    "We require a number of parameters in the calculations that follow, so we'll define them all here. These are:\n",
    "- Image sizes\n",
    "- Various transmitted pulse parameters used to synthesize a replica Tx pulse\n",
    "- Sample rates in range and azimuth\n",
    "- The fast time $\\tau$ associated with each range sample along a range line, and the corresponding slant range of closest approach $R_{0}$ for each of these range samples\n",
    "- The frequency axes in range $f_{\\tau}$ and azimuth $f_{\\eta}$ after transforming our array to the frequency domain\n",
    "- The effective spacecraft velocity $V_{r}$. This is a psuedo velocity approximated by $V_{r} \\approx \\sqrt{V_{s} V_{g}}$, where $V_{s}$ is the norm of the satellite velocity vector, and $V_{g}$ is the antenna beam velocity projected onto the ground. $V_{g}$ is calculated numerically acording to the method defined in https://iopscience.iop.org/article/10.1088/1757-899X/1172/1/012012/pdf. Note that $V_{g}$ and hence $V_{r}$ varies by slant range.\n",
    "- The cosine of the instantaneous squint angle $D(f_{\\eta}, V_{r})$, where\n",
    "\n",
    "$$D(f_{\\eta}, V_{r}) = \\sqrt{1 - \\frac{c^{2} f_{\\eta}^{2}}{4 V_{r}^{2} f_{0}^{2}}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a7a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_range_line = radar_data.shape[1]\n",
    "len_az_line = radar_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len_range_line)\n",
    "print(len_az_line)\n",
    "\n",
    "# Tx pulse parameters\n",
    "c = sentinel1decoder.constants.SPEED_OF_LIGHT_MPS\n",
    "RGDEC = selection[\"Range Decimation\"].unique()[0]\n",
    "PRI = selection[\"PRI\"].unique()[0]\n",
    "rank = selection[\"Rank\"].unique()[0]\n",
    "suppressed_data_time = 320/(8*sentinel1decoder.constants.F_REF)\n",
    "range_start_time = selection[\"SWST\"].unique()[0] + suppressed_data_time\n",
    "wavelength = sentinel1decoder.constants.TX_WAVELENGTH_M\n",
    "\n",
    "# Sample rates\n",
    "range_sample_freq = sentinel1decoder.utilities.range_dec_to_sample_rate(RGDEC)\n",
    "range_sample_period = 1/range_sample_freq\n",
    "az_sample_freq = 1 / PRI\n",
    "az_sample_period = PRI\n",
    "\n",
    "# Fast time vector - defines the time axis along the fast time direction\n",
    "sample_num_along_range_line = np.arange(0, len_range_line, 1)\n",
    "fast_time_vec = range_start_time + (range_sample_period * sample_num_along_range_line)\n",
    "\n",
    "# Slant range vector - defines R0, the range of closest approach, for each range cell\n",
    "slant_range_vec = ((rank * PRI) + fast_time_vec) * c/2\n",
    "    \n",
    "# Axes - defines the frequency axes in each direction after FFT\n",
    "SWL = len_range_line/range_sample_freq\n",
    "az_freq_vals = np.arange(-az_sample_freq/2, az_sample_freq/2, 1/(PRI*len_az_line))\n",
    "range_freq_vals = np.arange(-range_sample_freq/2, range_sample_freq/2, 1/SWL)\n",
    " \n",
    "# Spacecraft velocity - numerical calculation of the effective spacecraft velocity\n",
    "ecef_vels = l0file.ephemeris.apply(lambda x: math.sqrt(x[\"X-axis velocity ECEF\"]**2 + x[\"Y-axis velocity ECEF\"]**2 +x[\"Z-axis velocity ECEF\"]**2), axis=1)\n",
    "velocity_interp = interp1d(l0file.ephemeris[\"POD Solution Data Timestamp\"].unique(), ecef_vels.unique(), fill_value=\"extrapolate\")\n",
    "x_interp = interp1d(l0file.ephemeris[\"POD Solution Data Timestamp\"].unique(), l0file.ephemeris[\"X-axis position ECEF\"].unique(), fill_value=\"extrapolate\")\n",
    "y_interp = interp1d(l0file.ephemeris[\"POD Solution Data Timestamp\"].unique(), l0file.ephemeris[\"Y-axis position ECEF\"].unique(), fill_value=\"extrapolate\")\n",
    "z_interp = interp1d(l0file.ephemeris[\"POD Solution Data Timestamp\"].unique(), l0file.ephemeris[\"Z-axis position ECEF\"].unique(), fill_value=\"extrapolate\")\n",
    "space_velocities = selection.apply(lambda x: velocity_interp(x[\"Coarse Time\"] + x[\"Fine Time\"]), axis=1).to_numpy().astype(float)\n",
    "\n",
    "x_positions = selection.apply(lambda x: x_interp(x[\"Coarse Time\"] + x[\"Fine Time\"]), axis=1).to_numpy().astype(float)\n",
    "y_positions = selection.apply(lambda x: y_interp(x[\"Coarse Time\"] + x[\"Fine Time\"]), axis=1).to_numpy().astype(float)\n",
    "z_positions = selection.apply(lambda x: z_interp(x[\"Coarse Time\"] + x[\"Fine Time\"]), axis=1).to_numpy().astype(float)\n",
    "\n",
    "position_array = np.transpose(np.vstack((x_positions, y_positions, z_positions)))\n",
    "\n",
    "a = sentinel1decoder.constants.WGS84_SEMI_MAJOR_AXIS_M\n",
    "b = sentinel1decoder.constants.WGS84_SEMI_MINOR_AXIS_M\n",
    "H = np.linalg.norm(position_array, axis=1)\n",
    "W = np.divide(space_velocities, H)\n",
    "lat = np.arctan(np.divide(position_array[:, 2], position_array[:, 0]))\n",
    "local_earth_rad = np.sqrt(\n",
    "    np.divide(\n",
    "        (np.square(a**2 * np.cos(lat)) + np.square(b**2 * np.sin(lat))),\n",
    "        (np.square(a * np.cos(lat)) + np.square(b * np.sin(lat)))\n",
    "    )\n",
    ")\n",
    "cos_beta = (np.divide(np.square(local_earth_rad) + np.square(H) - np.square(slant_range_vec[:, np.newaxis]) , 2 * local_earth_rad * H))\n",
    "ground_velocities = local_earth_rad * W * cos_beta\n",
    "\n",
    "effective_velocities = np.sqrt(space_velocities * ground_velocities)\n",
    "\n",
    "D = np.sqrt(\n",
    "    1 - np.divide(\n",
    "        wavelength**2 * np.square(az_freq_vals),\n",
    "        4 * np.square(effective_velocities)\n",
    "    )\n",
    ").T\n",
    "\n",
    "# We're only interested in keeping D, so free up some memory by deleting these large arrays.\n",
    "del effective_velocities\n",
    "del ground_velocities\n",
    "del cos_beta\n",
    "del local_earth_rad\n",
    "del H\n",
    "del W\n",
    "del lat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adf6f0",
   "metadata": {},
   "source": [
    "### 4.2 - Convert data to 2D frequency domain\n",
    "\n",
    "We're going to be doing almost all our calculations in the frequency domain, so the first step is to FFT along the azimuth and range axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT each range line\n",
    "radar_data = np.fft.fft(radar_data, axis=1)\n",
    "# FFT each azimuth line\n",
    "radar_data = np.fft.fftshift(np.fft.fft(radar_data, axis=0), axes=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1539c33",
   "metadata": {},
   "source": [
    "### 4.3 - Range compression - create and apply matched filter\n",
    "\n",
    "Range compression is relatively simple. Range information is encoded in the arrival time of the pulse echo (i.e. an echo from a target further away will take longer to arrive), so by applying a matched filter consisting of the transmitted pulse, we can effectively focus the image along the range axis.\n",
    "\n",
    "We can synthesize a replica of the Tx pulse from parameters specified in the packet metadata. Since we're operating in the frequency domain, we also need to transform our pulse replica that we're using as a matched filter to the frequency domain, then take the complex conjugate. FInally, we need to multiply every range line by our matched filter.\n",
    "\n",
    "The Tx pulse replica is given by\n",
    "\n",
    "$$\\text{Tx Pulse} = exp\\biggl\\{2i\\pi\\Bigl(\\bigl(\\text{TXPSF} + \\frac{\\text{TXPRR  TXPL}}{2}\\bigl)\\tau + \\frac{\\text{TXPRR}}{2}\\tau^{2}\\Bigl)\\biggl\\}$$\n",
    "\n",
    "where $\\text{TXPSF}$ is the Tx Pulse Start Frequency, $\\text{TXPRR}$ is the Tx Pulse Ramp Rate, and $\\text{TXPL}$ is the Tx Pulse Length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05747c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create replica pulse\n",
    "TXPSF = selection[\"Tx Pulse Start Frequency\"].unique()[0]\n",
    "TXPRR = selection[\"Tx Ramp Rate\"].unique()[0]\n",
    "TXPL = selection[\"Tx Pulse Length\"].unique()[0]\n",
    "num_tx_vals = int(TXPL*range_sample_freq)\n",
    "tx_replica_time_vals = np.linspace(-TXPL/2, TXPL/2, num=num_tx_vals)\n",
    "phi1 = TXPSF + TXPRR*TXPL/2\n",
    "phi2 = TXPRR/2\n",
    "tx_replica = np.exp(2j * np.pi * (phi1*tx_replica_time_vals + phi2*tx_replica_time_vals**2))\n",
    "\n",
    "# Create range filter from replica pulse\n",
    "range_filter = np.zeros(len_range_line, dtype=complex)\n",
    "\n",
    "index_start = np.ceil((len_range_line - num_tx_vals) / 2)-1\n",
    "index_end = num_tx_vals + np.ceil((len_range_line - num_tx_vals) / 2)-2\n",
    "\n",
    "range_filter[int(index_start):int(index_end+1)] = tx_replica\n",
    "range_filter = np.conjugate(np.fft.fft(range_filter))\n",
    "\n",
    "# Apply filter\n",
    "radar_data = np.multiply(radar_data, range_filter)\n",
    "\n",
    "del range_filter\n",
    "del tx_replica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d543f",
   "metadata": {},
   "source": [
    "### 4.4 - Range cell migration correction\n",
    "\n",
    "Since the collector motion couples range and azimuth information, point targets will tend to produce returns spread in arcs across multiple range bins as the azimuth varies. We therefore need to apply a shift to align the phase history associated with each pointlike target into a single range bin, so we can then operate 1-dimensionally along the azimuth axis to perform azimuth compresison.\n",
    "\n",
    "The RCMC shift is defined by\n",
    "\n",
    "$$\\text{RCMC shift} = R_{0} \\biggl(\\frac{1}{D} - 1\\biggl)$$\n",
    "\n",
    "with $D$ being the cosine of the instantaneous squint angle and $R_{0}$ the range of closest approach, both defined in section 4.1. Since we're still operating in the frequency domain we need to apply a filter of the form\n",
    "\n",
    "$$\\text{RCMC filter} = exp\\biggl\\{4i\\pi\\frac{f_{\\tau}}{c}\\bigl(\\text{RCMC shift}\\bigl)\\biggl\\}$$\n",
    "\n",
    "Again, this needs to be multiplied by every range line in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RCMC filter\n",
    "range_freq_vals = np.linspace(-range_sample_freq/2, range_sample_freq/2, num=len_range_line)\n",
    "rcmc_shift = slant_range_vec[0] * (np.divide(1, D) - 1)\n",
    "rcmc_filter = np.exp(4j * np.pi * range_freq_vals * rcmc_shift / c)\n",
    "\n",
    "# Apply filter\n",
    "radar_data = np.multiply(radar_data, rcmc_filter)\n",
    "\n",
    "del rcmc_shift\n",
    "del rcmc_filter\n",
    "del range_freq_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7eb28",
   "metadata": {},
   "source": [
    "### 4.5 - Convert to range-Doppler domain\n",
    "\n",
    "We've finished processing the image in range, so we can inverse FFT back to the range domain along the range axis. The image will still be in the frequency domain in azimuth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data = np.fft.ifftshift(np.fft.ifft(radar_data, axis=1), axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81176bac",
   "metadata": {},
   "source": [
    "### 4.6 - Azimuth compression - create and apply matched filter\n",
    "\n",
    "Our azimuth filter is defined by\n",
    "\n",
    "$$\\text{Azimuth filter} = exp\\biggl\\{4i\\pi\\frac{R_{0}D(f_{\\eta}, V_{r})}{\\lambda}\\biggl\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab74952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter\n",
    "az_filter = np.exp(4j * np.pi * slant_range_vec * D / wavelength)\n",
    "\n",
    "# Apply filter\n",
    "radar_data = np.multiply(radar_data, az_filter)\n",
    "\n",
    "del az_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ef5da-d1e2-4b52-bd2e-d3c40ada6370",
   "metadata": {},
   "source": [
    "### 4.7 - Transform back to range-azimuth domain\n",
    "\n",
    "Finally, we'll transform back out of the frequency domain by taking the inverse FFT of each azimuth line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63015877-8aae-4535-85ed-adc712e1c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data = np.fft.ifft(radar_data, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc7422",
   "metadata": {},
   "source": [
    "## 5 - Plot Results - Import water binary map\n",
    "\n",
    "With azimuth compression complete, we're ready to plot our image!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33c12a",
   "metadata": {},
   "source": [
    "#### 5.1 - save binary map and scene image as npy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Open the downloaded image with rasterio\n",
    "with rasterio.open('Clipped_Image_box.tif') as src:\n",
    "    water_array = src.read(1)  # read the first band\n",
    "    meta_data = src.meta\n",
    "\n",
    "np.save('water_body_map.npy', water_array)\n",
    "np.save('scene_image.npy', abs(radar_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d869f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_water_body = np.load('water_body_map.npy')  # Replace with your numpy array\n",
    "image_scene = np.flipud(np.log10(np.load('scene_image.npy') + 1))\n",
    "\n",
    "num_rows_to_remove = int(0.3 * image_water_body.shape[0])\n",
    "image_water_body = image_water_body[:-num_rows_to_remove]\n",
    "\n",
    "num_rows_to_remove = int(0.7 * image_water_body.shape[0])\n",
    "image_water_body = image_water_body[num_rows_to_remove:]\n",
    "\n",
    "num_rows_to_remove = int(0.3 * image_scene.shape[0])\n",
    "image_scene = image_scene[:-num_rows_to_remove]\n",
    "\n",
    "num_cols_to_remove = int(0.65 * image_water_body.shape[1])\n",
    "image_water_body = image_water_body[:, :-num_cols_to_remove]\n",
    "\n",
    "num_cols_to_remove = int(0.45 * image_water_body.shape[1])\n",
    "image_water_body = image_water_body[:, num_cols_to_remove:]\n",
    "\n",
    "# Define the downsampling factor (e.g., reduce by a factor of 2)\n",
    "downsample_factor = 0.5\n",
    "original_height, original_width = image_scene.shape[:2]\n",
    "new_width = int(original_width * downsample_factor)\n",
    "new_height = int(original_height * downsample_factor)\n",
    "downsampled_image = cv2.resize(image_scene, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "image_scene = cv2.resize(downsampled_image, (original_width, original_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Define the downsampling factor (e.g., reduce by a factor of 2)\n",
    "downsample_factor = 0.5\n",
    "original_height, original_width = image_water_body.shape[:2]\n",
    "new_width = int(original_width * downsample_factor)\n",
    "new_height = int(original_height * downsample_factor)\n",
    "downsampled_image = cv2.resize(image_water_body, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "image_water_body = cv2.resize(downsampled_image, (original_width, original_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Save or display the result\n",
    "# cv2.imwrite('output_image.png', image_scene)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image_scene, cmap='viridis')\n",
    "\n",
    "image_water_body = np.where(image_water_body==0, 1, image_water_body)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('water_map')\n",
    "plt.imshow(image_water_body, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "def normalise(input):\n",
    "    return (input - input.min()) / (input.max() - input.min())\n",
    "\n",
    "def otsu_thresholding(image):\n",
    "    image_8bit = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    threshold_value, binary_image = cv2.threshold(image_8bit, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image, threshold_value\n",
    "\n",
    "# Perform otsu thresholding\n",
    "S1_CLIPP = 0.5  # Clip threshold\n",
    "image_scene = normalise(image_scene)\n",
    "image_scene_clipped = normalise(np.clip(image_scene, 0, S1_CLIPP))\n",
    "\n",
    "binary_diff, threshold_value = otsu_thresholding(image_scene_clipped)\n",
    "\n",
    "#binary_diff = np.where(binary_diff > threshold_value, 1, 0)\n",
    "binary_diff = np.where(binary_diff==0, 1, 0)\n",
    "print(threshold_value)\n",
    "\n",
    "if binary_diff.dtype != np.uint8:\n",
    "    binary_diff = (binary_diff > 0).astype(np.uint8) * 255\n",
    "\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_diff, connectivity=8)\n",
    "\n",
    "min_size = 100000  # You can change this value according to your requirement\n",
    "filtered_map = np.zeros_like(binary_diff)\n",
    "\n",
    "for label in range(1, num_labels):  # Start from 1 to skip the background component\n",
    "    if stats[label, cv2.CC_STAT_AREA] >= min_size:\n",
    "        # If the component's area is greater than or equal to min_size, keep it\n",
    "        filtered_map[labels == label] = 1\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('binary_diff')\n",
    "plt.imshow(binary_diff, cmap='viridis')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('filtered_map')\n",
    "plt.imshow(filtered_map, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "np.save('filtered_map.npy', filtered_map)\n",
    "np.save('image_water_body.npy', image_water_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "image_water_body = np.load('image_water_body.npy')\n",
    "filtered_map = np.load('filtered_map.npy')\n",
    "\n",
    "def adjust_brightness(img):\n",
    "    norm_img = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    norm_img = np.uint8(norm_img)\n",
    "    return norm_img\n",
    "\n",
    "def resize_image(img, max_width=800, max_height=800):\n",
    "    height, width = img.shape[:2]\n",
    "    scaling_factor = min(max_width / width, max_height / height)\n",
    "    new_width = int(width * scaling_factor)\n",
    "    new_height = int(height * scaling_factor)\n",
    "    resized_img = cv2.resize(img, (new_width, new_height))\n",
    "    return resized_img, scaling_factor\n",
    "\n",
    "def select_points(img, max_width=800, max_height=800):\n",
    "    bright_img = adjust_brightness(img)\n",
    "    resized_img, scaling_factor = resize_image(bright_img, max_width, max_height)\n",
    "    clone = resized_img.copy()\n",
    "    points = []\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(clone, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow(\"Image\", clone)\n",
    "\n",
    "    cv2.imshow(\"Image\", clone)\n",
    "    cv2.setMouseCallback(\"Image\", mouse_callback)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # Scale points back to original image size\n",
    "    original_points = [(int(x / scaling_factor), int(y / scaling_factor)) for (x, y) in points]\n",
    "    return original_points\n",
    "\n",
    "def align_images_manual(img1, img2, points1, points2, background_value=0, matrix_file='affine_matrix.json'):\n",
    "    if os.path.exists(matrix_file):\n",
    "        with open(matrix_file, 'r') as f:\n",
    "            matrix = np.array(json.load(f))\n",
    "    else:\n",
    "        points1 = np.array(points1, dtype=np.float32)\n",
    "        points2 = np.array(points2, dtype=np.float32)\n",
    "\n",
    "        # Compute affine transformation matrix using more points\n",
    "        matrix, _ = cv2.estimateAffinePartial2D(points2, points1)\n",
    "        \n",
    "        # Save the transformation matrix\n",
    "        with open(matrix_file, 'w') as f:\n",
    "            json.dump(matrix.tolist(), f)\n",
    "\n",
    "    # Apply affine transformation to the second image\n",
    "    aligned_img = cv2.warpAffine(img2, matrix, (img1.shape[1], img1.shape[0]), borderMode=cv2.BORDER_CONSTANT, borderValue=background_value)\n",
    "    \n",
    "    # Apply affine transformation to the mask\n",
    "    mask = np.ones_like(img2, dtype=np.uint8) * 255\n",
    "    aligned_mask = cv2.warpAffine(mask, matrix, (img1.shape[1], img1.shape[0]), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "    # Combine the aligned image with the first image\n",
    "    combined_image = np.where(aligned_mask == 255, aligned_img * 2, background_value)\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Load images\n",
    "img1 = image_water_body\n",
    "img2 = filtered_map\n",
    "\n",
    "# Ensure images are loaded properly\n",
    "if img1 is None or img2 is None:\n",
    "    print(\"Error loading images\")\n",
    "    exit()\n",
    "\n",
    "# Select points manually on both images\n",
    "print(\"Select 3 points on the first image\")\n",
    "points1 = select_points(img1.copy())\n",
    "\n",
    "print(\"Select the corresponding 3 points on the second image\")\n",
    "points2 = select_points(img2.copy())\n",
    "\n",
    "# Align images\n",
    "background_value = 0.5  # Background value is 0\n",
    "aligned_image = align_images_manual(img1, img2, points1, points2, background_value)\n",
    "\n",
    "# Display the aligned image\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title('Image 1')\n",
    "plt.imshow(img1)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title('Image 2')\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title('Aligned Image 2')\n",
    "plt.imshow(aligned_image)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title('Aligned Image - Map')\n",
    "plt.imshow(aligned_image - img1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406178e5",
   "metadata": {},
   "source": [
    "There are still a few noteworthy issues with our image. The first is folding - notice various terrain features from the top of the image are folded into the bottom, and terrain from the left of the image is folded into the right side. Folding in range (range ambiguities) occurs due to echoes spilling over into earlier or later sampling windows. Folding in azimuth occurs due to our sampling the azimuth spectrum of the scene at the PRF, which leads to folding in the frequency spectrum.\n",
    "\n",
    "Various terrain features are clearly visible, however the image is still not perfectly focused. We have assumed a Doppler centroid of 0Hz, and have not applied a number of additional processing steps that ESA use to produce Level 1 products e.g. Secondary Range Compression (SRC). These are left as an exercise for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Noise power calculator\n",
    "\n",
    "- Trying to use absolute power values instead of SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def db_to_linear(value_db):\n",
    "#     return 10 ** (value_db / 10)\n",
    "\n",
    "# def calculate_reference_power(P_t, G_t_db, G_r_db, wavelength, sigma, R, L):\n",
    "#     # Convert gains from dB to linear scale\n",
    "#     G_t = db_to_linear(G_t_db)\n",
    "#     G_r = db_to_linear(G_r_db)    \n",
    "#     P_r = (P_t * G_t * G_r * (wavelength ** 2) * sigma) / ((4 * math.pi) ** 3 * R ** 4 * L)\n",
    "#     return P_r\n",
    "\n",
    "# def calculate_additional_noise_power_from_nesz(original_nesz_db, desired_nesz_db, ref_power):\n",
    "#     # Convert NESZ from dB to linear scale\n",
    "#     original_nesz_linear = db_to_linear(original_nesz_db)\n",
    "#     desired_nesz_linear = db_to_linear(desired_nesz_db)\n",
    "    \n",
    "#     # Calculate the additional noise power needed\n",
    "#     additional_noise_power = ref_power * (desired_nesz_linear - original_nesz_linear)\n",
    "#     return additional_noise_power\n",
    "\n",
    "# # Sentinel-1 Specifications\n",
    "# P_t = 280  # Transmitted power in watts\n",
    "# G_t_db = 80  # Transmitting antenna gain in dB\n",
    "# G_r_db = 80  # Receiving antenna gain in dB\n",
    "# wavelength = 0.05551712  # Wavelength in meters (5.4 GHz frequency)\n",
    "# sigma = 1  # RCS in square meters\n",
    "# R = 200e3  # Range in meters\n",
    "# L_sentinel = db_to_linear(3)  # System losses (linear scale)\n",
    "# sentinel_NESZ = -22\n",
    "\n",
    "# sentinel_expected_power = calculate_reference_power(P_t, G_t_db, G_r_db, wavelength, sigma, R, L_sentinel)\n",
    "\n",
    "# mean_value = np.mean(abs(radar_data)**2)\n",
    "\n",
    "# print(\"Mean image value:\", mean_value)\n",
    "# print(\"Sentinel reference power:\", sentinel_expected_power)\n",
    "\n",
    "# # Capella Satellite Specifications\n",
    "# Pt_capella = 10  # Transmitted power in watts\n",
    "# gain_db_capella = 46\n",
    "# G_capella = db_to_linear(gain_db_capella)  # Antenna gain (linear scale)\n",
    "# wavelength_capella = 0.03189281  # Wavelength in meters (9.4 GHz frequency)\n",
    "# R_capella = 200e3  # Range to the target in meters\n",
    "# L_capella = db_to_linear(5)  # System losses (linear scale)\n",
    "# capella_NESZ = -17\n",
    "\n",
    "# ref_power = calculate_reference_power(Pt_capella, gain_db_capella, gain_db_capella, wavelength_capella, 1, R_capella, L_capella)\n",
    "# print(\"Capella reference power:\", ref_power)\n",
    "\n",
    "# # Convert NESZ values to linear scale\n",
    "# nesz_original_db = -22\n",
    "# nesz_new_db = -17\n",
    "# nesz_original_linear = 10**(nesz_original_db / 10)\n",
    "# nesz_new_linear = 10**(nesz_new_db / 10)\n",
    "\n",
    "# # Calculate the new noise power\n",
    "# additional_noise_power = nesz_new_linear*mean_value\n",
    "# #additional_noise_power = calculate_additional_noise_power_from_nesz(sentinel_NESZ, capella_NESZ, sentinel_expected_power)\n",
    "\n",
    "# print(\"Additional noise power pre-scaling:\", additional_noise_power)\n",
    "\n",
    "# # Generate complex Gaussian noise\n",
    "# def generate_thermal_noise(shape, sigma):\n",
    "#     noise_real = np.random.normal(0, sigma, shape)\n",
    "#     noise_imag = np.random.normal(0, sigma, shape)\n",
    "#     return noise_real + 1j * noise_imag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
